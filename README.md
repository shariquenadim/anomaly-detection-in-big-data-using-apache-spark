# anomaly-detection-in-big-data-using-apache-spark
Explore anomaly detection in big data with Apache Spark. Detect outliers and unusual patterns efficiently using scalable distributed computing. Harness the power of Spark's parallel processing to analyze vast datasets and identify anomalies, ensuring data integrity and security.

Abstract—In today’s rapidly advancing digital landscape,
where data growth surpasses historical benchmarks, innovative
structures are required for efficient information retrieval from
vast Big Data repositories. The Hadoop ecosystem, including
HDFS, MapReduce, Hive, HBase, Pig, among others, addresses
these complexities. Acknowledging the constraints of MapReduce,
Apache Spark emerges as a pivotal player, processing data up
to 100 times faster on memory. This transformative capability
establishes Apache Spark as a key solution in the domain of
Big Data processing, offering unmatched efficiency and scalability. Amid global concerns of credit card fraud, particularly
in Bharat’s (India’s) expanding digital landscape, this paper
explores sophisticated anomaly detection techniques, focusing
on Isolation Forest and One-Class SVM algorithms. Practical
considerations influence the choice to implement both, ensuring
a balance between effectiveness and computational demands.
The analysis evaluates their performance, providing insights
into their suitability for credit card fraud detection within the
constraints of the dataset and available computational power.
Additionally, the research culminates in a nuanced exploration
of the results, shedding light on the strengths and limitations of
the Isolation Forest and One-Class SVM algorithms, as detailed
in the concluding section.
Index Terms—Big Data, Apache Spark, Isolation Forest, OneClass SVM, credit card, fraud detection.

**https://github.com/shariquenadim/anomaly-detection-in-big-data-using-apache-spark/blob/main/Final%20Paper.pdf**
